{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot_seqtoseq.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_Dllp2HLb0R"
      },
      "source": [
        "#importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Input,Embedding,Bidirectional,LSTM,Dense,Concatenate\n",
        "from keras.models import Model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s89W8JYPGGE",
        "outputId": "d06143f0-30e6-4969-d3ea-f123d7517bb7"
      },
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "zcWtqLvNMO8A",
        "outputId": "796b42d5-10b7-4788-dc77-b3d470f4f87b"
      },
      "source": [
        "dataset = pd.read_csv(\"dialogs.txt\",names=[\"question\",\"answer\"],sep='\\t')\n",
        "print(dataset.shape)\n",
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3725, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi, how are you doing?</td>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>i've been great. what about you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              question                                    answer\n",
              "0               hi, how are you doing?             i'm fine. how about yourself?\n",
              "1        i'm fine. how about yourself?       i'm pretty good. thanks for asking.\n",
              "2  i'm pretty good. thanks for asking.         no problem. so how have you been?\n",
              "3    no problem. so how have you been?          i've been great. what about you?\n",
              "4     i've been great. what about you?  i've been good. i'm in school right now."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7NloxgIMfR6",
        "outputId": "6f4c985d-259c-43a8-eb0e-3880e72f2049"
      },
      "source": [
        "#checking and removing any duplicated rows\n",
        "print(dataset.isna().sum())\n",
        "print(\"---\"*10)\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "print(\"Duplicate data present in dataframe :\",dataset.duplicated().sum())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question    0\n",
            "answer      0\n",
            "dtype: int64\n",
            "------------------------------\n",
            "Duplicate data present in dataframe : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Pd-xNRuOM6JI",
        "outputId": "42416ae4-76f9-4870-93d0-24f7a5e613cf"
      },
      "source": [
        "#convert the question and answer to lower case\n",
        "\n",
        "dataset['question']=dataset['question'].str.lower()\n",
        "dataset['answer']=dataset['answer'].str.lower()\n",
        "\n",
        "#add SOS and EOS token for the encoder and decoder structure \n",
        "dataset['decoder_input'] = dataset.answer.apply(lambda x: 'sos '+x)\n",
        "dataset['decoder_label'] = dataset.answer.apply(lambda x: x+' eo>')\n",
        "dataset.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>decoder_input</th>\n",
              "      <th>decoder_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi, how are you doing?</td>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>sos i'm fine. how about yourself?</td>\n",
              "      <td>i'm fine. how about yourself? eo&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>sos i'm pretty good. thanks for asking.</td>\n",
              "      <td>i'm pretty good. thanks for asking. eo&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>sos no problem. so how have you been?</td>\n",
              "      <td>no problem. so how have you been? eo&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>sos i've been great. what about you?</td>\n",
              "      <td>i've been great. what about you? eo&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "      <td>sos i've been good. i'm in school right now.</td>\n",
              "      <td>i've been good. i'm in school right now. eo&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              question  ...                                 decoder_label\n",
              "0               hi, how are you doing?  ...             i'm fine. how about yourself? eo>\n",
              "1        i'm fine. how about yourself?  ...       i'm pretty good. thanks for asking. eo>\n",
              "2  i'm pretty good. thanks for asking.  ...         no problem. so how have you been? eo>\n",
              "3    no problem. so how have you been?  ...          i've been great. what about you? eo>\n",
              "4     i've been great. what about you?  ...  i've been good. i'm in school right now. eo>\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp7rV2iRNs9i",
        "outputId": "73f348db-e527-4ff1-c721-17682f231336"
      },
      "source": [
        "question=[]\n",
        "for i in dataset['question']:\n",
        "    question.append(word_tokenize(i))\n",
        "    \n",
        "decoder_input=[]\n",
        "for i in dataset['decoder_input']:\n",
        "    decoder_input.append(word_tokenize(i))\n",
        "    \n",
        "\n",
        "    \n",
        "decoder_label=[]\n",
        "for i in dataset['decoder_label']:\n",
        "    decoder_label.append(word_tokenize(i))\n",
        "    \n",
        "\n",
        "\n",
        "print(len(question),len(decoder_input),len(decoder_label))\n",
        "\n",
        "#create a vocabulary set\n",
        "\n",
        "vocab = set()\n",
        "for ques in question:\n",
        "    vocab=vocab.union(set(ques))\n",
        "\n",
        "for ans in decoder_input:\n",
        "    vocab=vocab.union(set(ans))\n",
        "    \n",
        "for ans in decoder_label:\n",
        "    vocab=vocab.union(set(ans))\n",
        "    \n",
        "\n",
        "    \n",
        "#print(vocab)\n",
        "print(\"Length of the vocab :\",len(vocab))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3724 3724 3724\n",
            "Length of the vocab : 2511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTlanjWxQ9kB",
        "outputId": "1378ea43-6980-42b9-b9ab-8b9f85fb1c39"
      },
      "source": [
        "#increase the vocab size + 1  for padding \n",
        "vocab_size = len(vocab) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S8J7_K3RbL8",
        "outputId": "829ad3d2-c5ca-4354-f814-b98933823116"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)\n",
        "\n",
        "print(type(tokenizer.word_index))\n",
        "disp=list(tokenizer.word_index.items())[:30]\n",
        "print(\"First 30 tokens with their respective indexes \")\n",
        "print(disp)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "First 30 tokens with their respective indexes \n",
            "[('candy', 1), ('nation', 2), ('predictable', 3), ('news', 4), ('leftovers', 5), ('blows', 6), ('as', 7), ('passenger', 8), ('angry', 9), ('no', 10), ('offer', 11), ('barking', 12), ('theaters', 13), ('finger', 14), ('talent', 15), ('jobs', 16), ('answered', 17), ('drawer', 18), ('vacuumed', 19), ('office', 20), ('broke', 21), ('scrub', 22), ('lessons', 23), ('sleeve', 24), ('waiter', 25), ('needs', 26), ('rained', 27), ('boy', 28), ('genes', 29), ('oranges', 30)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV_AhGfjD5nk",
        "outputId": "0b9d86e5-b1fa-4b0d-f46d-be7bece42847"
      },
      "source": [
        "#mapping the tokens with the id\n",
        "train_encoder_input = tokenizer.texts_to_sequences(question)\n",
        "train_decoder_input=tokenizer.texts_to_sequences(decoder_input)\n",
        "train_decoder_label=tokenizer.texts_to_sequences(decoder_label)\n",
        "\n",
        "print(question[0])\n",
        "print(train_encoder_input[0])\n",
        "print(\"---\"*5)\n",
        "print(decoder_input[0])\n",
        "print(train_decoder_input[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hi', ',', 'how', 'are', 'you', 'doing', '?']\n",
            "[2270, 1259, 1113, 991, 793, 2485, 1510]\n",
            "---------------\n",
            "['sos', 'i', \"'m\", 'fine', '.', 'how', 'about', 'yourself', '?']\n",
            "[326, 1083, 719, 2246, 1508, 1113, 1764, 2024, 1510]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uouSzH_4Eg5E",
        "outputId": "e4058bbd-faf5-4160-ced2-a25b45936874"
      },
      "source": [
        "\n",
        "maximum_encoder_input=np.array([len(s) for s in train_encoder_input]).max()\n",
        "maximum_decoder_input=np.array([len(s) for s in train_decoder_input]).max()\n",
        "maximum__decoder_label=np.array([len(s) for s in train_decoder_label]).max()\n",
        "print(maximum_encoder_input,maximum_decoder_input,maximum__decoder_label)\n",
        "\n",
        "# padding the vectors so that all vectors are of equal length\n",
        "train_encoder_input = pad_sequences(train_encoder_input,maxlen=maximum_encoder_input)\n",
        "train_decoder_input = pad_sequences(train_decoder_input,maxlen=maximum_decoder_input)\n",
        "train_decoder_label = pad_sequences(train_decoder_label,maxlen=maximum_decoder_input)\n",
        "\n",
        "print(train_encoder_input.shape)\n",
        "print(train_decoder_input.shape)\n",
        "print(train_decoder_label.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 23 24\n",
            "(3724, 22)\n",
            "(3724, 23)\n",
            "(3724, 23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqt6eCtEGEn7"
      },
      "source": [
        "Encoder input --- > Encoder embedding   ----> LSTM ---->LSTM ---->LSTM ---->Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgrPincAFWzN",
        "outputId": "e87dc52e-5cb6-4b61-972e-a0b3575c4b79"
      },
      "source": [
        "embedding_size=128\n",
        "hidden_size = 128\n",
        "\n",
        "encoder_input = Input(shape=[maximum_encoder_input])\n",
        "#print(\"encoder_input shape : \",encoder_input)\n",
        "#print(\"---\")\n",
        "encoder_embedding = Embedding(vocab_size,embedding_size,mask_zero=True)\n",
        "encoder_embedded = encoder_embedding(encoder_input)\n",
        "#print(\"encoder_embedded shape : \",encoder_embedded)\n",
        "#print(\"---\")\n",
        "lstm1 = LSTM(hidden_size,return_sequences=True,return_state=True)\n",
        "encoder_output1,_,_ = lstm1(encoder_embedded)\n",
        "\n",
        "lstm2 = LSTM(hidden_size,return_sequences=True,return_state=True)\n",
        "encoder_output2,_,_ = lstm2(encoder_output1)\n",
        "print(\"manin : \", lstm2(encoder_output1))\n",
        "print(\"----------\")\n",
        "lstm3 = LSTM(hidden_size,return_sequences=True,return_state=True)\n",
        "encoder_output3,hs,cs = lstm3(encoder_output2)\n",
        "print(\"manin : \",encoder_output3)\n",
        "\n",
        "encoder_dense_c = Dense(hidden_size)\n",
        "encoder_c3 = encoder_dense_c(cs)\n",
        "print(encoder_c3)\n",
        "encoder_dense_h = Dense(hidden_size)\n",
        "encoder_h3 = encoder_dense_h(cs)\n",
        "print(encoder_h3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manin :  [<KerasTensor: shape=(None, 22, 128) dtype=float32 (created by layer 'lstm_1')>, <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm_1')>, <KerasTensor: shape=(None, 128) dtype=float32 (created by layer 'lstm_1')>]\n",
            "----------\n",
            "manin :  KerasTensor(type_spec=TensorSpec(shape=(None, 22, 128), dtype=tf.float32, name=None), name='lstm_2/PartitionedCall:1', description=\"created by layer 'lstm_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='dense/BiasAdd:0', description=\"created by layer 'dense'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='dense_1/BiasAdd:0', description=\"created by layer 'dense_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJwlhZGiJMoo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70LBRpfhJEnJ",
        "outputId": "94f66547-d872-4ded-afde-bb54a9836071"
      },
      "source": [
        "decoder_input = Input(shape=(None,))\n",
        "\n",
        "decoder_embedding = Embedding(vocab_size,embedding_size,mask_zero=True)\n",
        "decoder_embedded = decoder_embedding(decoder_input)\n",
        "\n",
        "print(\"decoder_embedded : \",decoder_embedded)\n",
        "print(\"-------------------\")\n",
        "\n",
        "decoder_lstm = LSTM(hidden_size,return_sequences=True,return_state=True)\n",
        "decoder_output,dh,dc = decoder_lstm(decoder_embedded,initial_state=[encoder_h3,encoder_c3])\n",
        "\n",
        "decoder_lstm1 = LSTM(hidden_size,return_sequences=True,return_state=True)\n",
        "decoder_output,dh,dc = decoder_lstm1(decoder_output)\n",
        "\n",
        "dense1 = Dense(200,activation='relu')\n",
        "decoder_output = dense1(decoder_output)\n",
        "\n",
        "softmax = Dense(vocab_size,activation='softmax')\n",
        "decoder_output = softmax(decoder_output)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_embedded :  KerasTensor(type_spec=TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None), name='embedding_1/embedding_lookup/Identity_1:0', description=\"created by layer 'embedding_1'\")\n",
            "-------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HrwHUo5KDrt",
        "outputId": "75d4dc7c-d45b-48ce-f9da-def4923ae19d"
      },
      "source": [
        "#defining an optimizer and training a model\n",
        "trainer = Model([encoder_input,decoder_input],decoder_output)\n",
        "trainer.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "train_hist = trainer.fit([train_encoder_input,train_decoder_input],train_decoder_label,epochs=30,validation_split=0.1,batch_size=128)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "27/27 [==============================] - 48s 1s/step - loss: 2.7066 - accuracy: 0.1036 - val_loss: 2.3384 - val_accuracy: 0.1042\n",
            "Epoch 2/30\n",
            "27/27 [==============================] - 22s 829ms/step - loss: 2.0530 - accuracy: 0.1085 - val_loss: 2.2749 - val_accuracy: 0.1042\n",
            "Epoch 3/30\n",
            "27/27 [==============================] - 22s 812ms/step - loss: 2.0089 - accuracy: 0.1183 - val_loss: 2.2580 - val_accuracy: 0.1223\n",
            "Epoch 4/30\n",
            "27/27 [==============================] - 22s 819ms/step - loss: 1.9670 - accuracy: 0.1363 - val_loss: 2.2269 - val_accuracy: 0.1310\n",
            "Epoch 5/30\n",
            "27/27 [==============================] - 22s 816ms/step - loss: 1.9300 - accuracy: 0.1441 - val_loss: 2.2034 - val_accuracy: 0.1332\n",
            "Epoch 6/30\n",
            "27/27 [==============================] - 22s 816ms/step - loss: 1.8840 - accuracy: 0.1943 - val_loss: 2.1463 - val_accuracy: 0.2187\n",
            "Epoch 7/30\n",
            "27/27 [==============================] - 22s 821ms/step - loss: 1.8243 - accuracy: 0.2384 - val_loss: 2.1222 - val_accuracy: 0.2291\n",
            "Epoch 8/30\n",
            "27/27 [==============================] - 22s 805ms/step - loss: 1.7952 - accuracy: 0.2462 - val_loss: 2.1446 - val_accuracy: 0.2372\n",
            "Epoch 9/30\n",
            "27/27 [==============================] - 22s 825ms/step - loss: 1.7719 - accuracy: 0.2586 - val_loss: 2.1455 - val_accuracy: 0.2517\n",
            "Epoch 10/30\n",
            "27/27 [==============================] - 22s 828ms/step - loss: 1.7404 - accuracy: 0.2701 - val_loss: 2.1599 - val_accuracy: 0.2570\n",
            "Epoch 11/30\n",
            "27/27 [==============================] - 22s 828ms/step - loss: 1.7196 - accuracy: 0.2787 - val_loss: 2.1673 - val_accuracy: 0.2542\n",
            "Epoch 12/30\n",
            "27/27 [==============================] - 23s 841ms/step - loss: 1.7006 - accuracy: 0.2858 - val_loss: 2.1791 - val_accuracy: 0.2575\n",
            "Epoch 13/30\n",
            "27/27 [==============================] - 22s 815ms/step - loss: 1.6878 - accuracy: 0.2897 - val_loss: 2.2060 - val_accuracy: 0.2584\n",
            "Epoch 14/30\n",
            "27/27 [==============================] - 22s 822ms/step - loss: 1.6751 - accuracy: 0.2915 - val_loss: 2.2021 - val_accuracy: 0.2542\n",
            "Epoch 15/30\n",
            "27/27 [==============================] - 22s 826ms/step - loss: 1.6654 - accuracy: 0.2937 - val_loss: 2.2104 - val_accuracy: 0.2570\n",
            "Epoch 16/30\n",
            "27/27 [==============================] - 22s 819ms/step - loss: 1.6580 - accuracy: 0.2945 - val_loss: 2.2231 - val_accuracy: 0.2483\n",
            "Epoch 17/30\n",
            "27/27 [==============================] - 22s 811ms/step - loss: 1.6496 - accuracy: 0.2976 - val_loss: 2.2695 - val_accuracy: 0.2615\n",
            "Epoch 18/30\n",
            "27/27 [==============================] - 22s 832ms/step - loss: 1.6396 - accuracy: 0.2989 - val_loss: 2.2667 - val_accuracy: 0.2609\n",
            "Epoch 19/30\n",
            "27/27 [==============================] - 22s 800ms/step - loss: 1.6311 - accuracy: 0.3003 - val_loss: 2.2727 - val_accuracy: 0.2561\n",
            "Epoch 20/30\n",
            "27/27 [==============================] - 22s 822ms/step - loss: 1.6202 - accuracy: 0.3019 - val_loss: 2.3275 - val_accuracy: 0.2592\n",
            "Epoch 21/30\n",
            "27/27 [==============================] - 22s 819ms/step - loss: 1.6150 - accuracy: 0.3033 - val_loss: 2.2940 - val_accuracy: 0.2595\n",
            "Epoch 22/30\n",
            "27/27 [==============================] - 22s 811ms/step - loss: 1.6050 - accuracy: 0.3045 - val_loss: 2.3172 - val_accuracy: 0.2631\n",
            "Epoch 23/30\n",
            "27/27 [==============================] - 22s 809ms/step - loss: 1.5963 - accuracy: 0.3068 - val_loss: 2.3387 - val_accuracy: 0.2589\n",
            "Epoch 24/30\n",
            "27/27 [==============================] - 22s 808ms/step - loss: 1.5864 - accuracy: 0.3083 - val_loss: 2.3453 - val_accuracy: 0.2609\n",
            "Epoch 25/30\n",
            "27/27 [==============================] - 22s 819ms/step - loss: 1.5753 - accuracy: 0.3099 - val_loss: 2.3524 - val_accuracy: 0.2603\n",
            "Epoch 26/30\n",
            "27/27 [==============================] - 22s 829ms/step - loss: 1.5657 - accuracy: 0.3132 - val_loss: 2.3451 - val_accuracy: 0.2534\n",
            "Epoch 27/30\n",
            "27/27 [==============================] - 23s 842ms/step - loss: 1.5616 - accuracy: 0.3141 - val_loss: 2.3879 - val_accuracy: 0.2603\n",
            "Epoch 28/30\n",
            "27/27 [==============================] - 22s 816ms/step - loss: 1.5520 - accuracy: 0.3160 - val_loss: 2.4077 - val_accuracy: 0.2626\n",
            "Epoch 29/30\n",
            "27/27 [==============================] - 23s 834ms/step - loss: 1.5417 - accuracy: 0.3179 - val_loss: 2.3979 - val_accuracy: 0.2556\n",
            "Epoch 30/30\n",
            "27/27 [==============================] - 22s 820ms/step - loss: 1.5402 - accuracy: 0.3198 - val_loss: 2.3904 - val_accuracy: 0.2531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9bSWSZlR6-J"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}